## KAI-BERT: An Educational BERT Implementation ğŸ“–

Welcome to KAI-BERT, a clear and academic-friendly implementation of BERT, designed to help researchers and engineers understand its building blocks without unnecessary complexity.

This project follows the classic BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (Devlin et al.) and focuses on clarity over speed, making it perfect for those who want to learn, experiment, and extend. ğŸš€

### ğŸ—ï¸ Whatâ€™s Inside?
- ğŸ§© Modeling BERT from scratch: Check out modeling.py to see the architecture unfold.
- ğŸ” Masked Language Modeling (MLM) training setup.
- ğŸ“œ Config-driven design: Hyperparameters and model settings live in configuration.py.
- âš¡ PyTorch Lightning for structured and modular training.

### ğŸ“‚ Project Structure
```
ğŸ“‚ kai-bert  
â”œâ”€â”€ data/  
â”‚   â”œâ”€â”€ config.json  # Model & training configs  
â”‚   â”œâ”€â”€ model.safetensors  # Pretrained weights  
â”œâ”€â”€ scripts/  # Utility scripts (training, evaluation, etc.)  
â”œâ”€â”€ src/  
â”‚   â”œâ”€â”€ bert.py  # Core BERT model  
â”‚   â”œâ”€â”€ configuration.py  # Model hyperparams  
â”‚   â”œâ”€â”€ modeling.py  # Educational breakdown of BERTâ€™s components  
â”‚   â”œâ”€â”€ modeling_outputs.py  # Utilities for handling model outputs  
â”‚   â”œâ”€â”€ __init__.py  # Python module  
â”œâ”€â”€ train.py  # Step-by-step training script for MLM ğŸ‹ï¸  
â”œâ”€â”€ playbook.ipynb  # Interactive notebook to experiment ğŸ­  
â”œâ”€â”€ playbook.py  # Script version of the notebook  
â”œâ”€â”€ .gitignore  # Keep things tidy  
â”œâ”€â”€ README.md  # You're reading this! ğŸ“–  
```
## ğŸš€ Installation & Setup
### 1ï¸âƒ£ Clone the repo
```bash
git clone https://github.com/abidikhairi/kai-bert.git  
cd kai-bert  
```

### 2ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt  
```

### 3ï¸âƒ£ Train your own BERT (step-by-step)

```bash
python train.py  
```


## âœ… To-Do List
### ğŸ“Œ Educational Enhancements:
- [ ] Add diagrams to explain BERT's computational graph ğŸ–¼ï¸
- [ ] Visualize Linear LR Scheduler ğŸ“‰

### ğŸ“Œ Training & Experimentation:
- [ ] Add train.py for Masked Language Modeling (MLM) ğŸ‹ï¸
- [ ] Implement custom data collator for efficient batching ğŸ“¦
- [ ] Experiment with different optimizers & schedulers âš¡

### ğŸ“Œ General Improvements:
- [ ] Add inference script for testing ğŸï¸
- [ ] Improve documentation with more explanations ğŸ“

## ğŸ¯ Who Is This For?
- âœ… Students & Researchers learning how BERT works under the hood.
- âœ… Engineers who want a structured, readable codebase for experimentation.
- âœ… Anyone curious about transformer architectures without the usual complexity.

This is not optimized for speed but instead prioritizes clarity and educational value.


## ğŸ¤– Contributions
Got a cool idea? Found a bug? PRs and issues are always welcome! ğŸ‰

